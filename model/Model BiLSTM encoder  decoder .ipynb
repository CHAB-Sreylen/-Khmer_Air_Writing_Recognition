{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.Preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.CustomDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.Model \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size // 2, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, n_features)\n",
    "        outputs, (h, c) = self.lstm(x)\n",
    "        # Concatenate the hidden states for both directions\n",
    "        h = torch.cat((h[-2], h[-1]), dim=1)\n",
    "        return outputs, h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, max_label_length, num_classes, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_label_length = max_label_length\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.out_layer = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, h, encoder_output):\n",
    "        # Prepare initial states\n",
    "        h = h.unsqueeze(0).repeat(self.num_layers, 1, 1)  # Repeat for each layer\n",
    "        c = torch.zeros_like(h)  # Initial cell states\n",
    "        # Prepare decoder inputs, initial hidden state only, inputs will be generated\n",
    "        inputs = torch.zeros(encoder_output.size(0), self.max_label_length, self.hidden_size).to(h.device)\n",
    "        outputs, (hn, cn) = self.lstm(inputs, (h, c))\n",
    "        outputs = self.out_layer(outputs)\n",
    "        outputs = outputs.transpose(1, 2)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_output, last_hidden_state = self.encoder(x)\n",
    "        decoder_output = self.decoder(last_hidden_state, encoder_output)\n",
    "        return decoder_output\n",
    "\n",
    "\n",
    "\n",
    "# Define the dimensions\n",
    "hidden_size = 1024\n",
    "batch_size = 32\n",
    "num_substrokes = 60\n",
    "substroke_length = 54\n",
    "num_classes =33\n",
    "max_label_length = 1\n",
    "dropout= 0.2\n",
    "num_layer= 3\n",
    "\n",
    "\n",
    "encoder = Encoder(input_size=substroke_length, hidden_size=hidden_size, num_layers=num_layer, dropout=dropout)\n",
    "decoder = Decoder(hidden_size=hidden_size, max_label_length=max_label_length, num_classes=num_classes, num_layers=num_layer, dropout=dropout)\n",
    "model = EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model=model.to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model, '\\n')\n",
    "\n",
    "# Test the updated model\n",
    "input_tensor = torch.randn(batch_size, num_substrokes, substroke_length).to(device)\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)  \n",
    "\n",
    "# Expected Shape: (batch_size,num_classes, max_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.Trainig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6.Evaluation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
